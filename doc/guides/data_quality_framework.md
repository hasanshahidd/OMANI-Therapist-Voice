
`markdown
<h1 align="center">ğŸ“Š Data Quality Framework â€” OMANIâ€‘Therapistâ€‘Voice</h1>

---

## ğŸ“¥ Introduction

The **OMANI-Therapist-Voice** project depends on a carefully curated and culturally sensitive dataset to ensure reliable emotion detection, safe interaction, and therapeutic accuracy in Omani Arabic. This framework documents how data is sourced, preprocessed, validated, and expanded â€” with integrated quality gates, monitoring, and GitHub upload hygiene.

---

## ğŸ“‚ Data Overview

### ğŸ§¾ Primary Dataset

- **File**: `data/mental_health_phrases.csv`  
- **Use**: Core training data for the `emotion_finetuned` model  
- **Content**: Annotated Omani phrases tagged with emotions like sadness, anger, and fear  
- **Scope**: Culturally aligned but currently limited to central dialects (expansion in progress)

---

## ğŸ§¹ Quality Assurance

### ğŸ§¼ Preprocessing

| Step              | Script                                | Description                                       |
|-------------------|----------------------------------------|---------------------------------------------------|
| Normalization     | `src/utils/text_normalization.py`     | Unifies Arabic variants, removes diacritics       |
| Tokenization      | `src/utils/tokenization.py`           | Custom Arabic-aware segmenter for LLM inputs      |
| Logging & Metrics | `src/utils/logger.py`, `monitoring.py`| Logs token counts, latency, and text deltas       |

### âœ… Validation

- **Annotation Accuracy**: Reviewed by native Omani speakers  
- **Model Evaluation**: Accuracy improvements tracked in `test_emotion_agent.py`  
- **Safety Sync**: Dataset aligned with `safety_agent.py` for suicide/harm trigger words  

---

## ğŸ“Š Quality Metrics

| Metric      | Source                         | Result                          |
|-------------|--------------------------------|---------------------------------|
| Emotion Accuracy | `docs/reports/annotation_metrics.md` | +15% vs. base model            |
| Text Consistency | `pipeline.log`             | Verified via preprocessing logs |
| Coverage     | Manual Audit                  | Missing regional dialects       |

---

## ğŸ§© Data Pipeline Flow

1. **Input**: Audio captured â†’ STT â†’ `transcript`  
2. **Process**: Transcript normalized & tokenized  
3. **Usage**:
   - Passed to `emotion_agent.py` and `safety_agent.py`
   - Informs response generation via `therapy_agent.py`
4. **Output**: Emotion-tagged, culturally adapted audio or crisis alert

---

## ğŸ§  Monitoring & Logging

- **Tool**: `src/utils/monitoring.py`  
- **Logs**: Stage latency, token count, success/failure  
- **Visibility**: All logs written to `pipeline.log` (excluded from GitHub)  
- **UI Hook**: Displayed in Flask app via `/logs` route for debugging (optional)

---

## ğŸ“ Project Structure (Partial)

```text
OMANI-Therapist-Voice/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ mental_health_phrases.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ emotion/
â”‚   â”‚       â””â”€â”€ emotion_agent.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ text_normalization.py
â”‚       â”œâ”€â”€ tokenization.py
â”‚       â””â”€â”€ monitoring.py
â””â”€â”€ tests/
    â””â”€â”€ unit/
        â””â”€â”€ test_emotion_agent.py
````

---

## ğŸš« GitHub Upload Guidelines

To protect privacy and keep the repo clean:

| Exclude File/Folder            | Reason                     |
| ------------------------------ | -------------------------- |
| `.env`                         | Contains API keys          |
| `venv/`                        | Machine-specific env       |
| `pipeline.log`                 | Regeneratable runtime logs |
| `output.wav`, `output_tts.wav` | Temp audio files           |
| `.vscode/`                     | Personal IDE settings      |
| `__pycache__` / `*.pyc`        | Python bytecode/cache      |

âœ… Confirm `.gitignore` contains all above.

---

## ğŸ›  Challenges & Fixes

| Challenge                   | Solution                                              |
| --------------------------- | ----------------------------------------------------- |
| Dialect scarcity in dataset | Expansion plan with region-specific samples           |
| Mislabels in emotional tags | Manual audits + unit tests in `test_emotion_agent.py` |
| Model inconsistencies       | Added custom tokenization + text normalization        |

---

## âœ… Best Practices

* Use dialectal examples from real Omani therapy sessions
* Re-run validation tests after each dataset update
* Back up `mental_health_phrases.csv` with each Git commit
* Collaborate with cultural experts when labeling ambiguous phrases

---

## ğŸš€ Future Enhancements

* Add emotion labels for compound expressions (e.g., shame + guilt)
* Expand with child/adolescent mental health phrases
* Integrate dialect detection to route phrases to region-specific LLM prompts
* Automate cultural bias scans using `docs/guides/bias_mitigation.md`

---

## ğŸ™ Acknowledgments

* **Hugging Face**: Arabic BERT architecture
* **xAI**: LLM therapy generation (Groq)
* **Azure**: Voice I/O and TTS processing
* **Omani Reviewers**: Phrase validation & dialect guidance

---
## ğŸ“Œ Summary

This document outlines how **OMANI-Therapist-Voice** achieves trustworthy, culturally respectful, and accurate emotion detection by managing its most critical asset â€” the **data**. Through normalization, annotation, and quality metrics, it lays the foundation for an emotionally intelligent and safe digital therapist.
