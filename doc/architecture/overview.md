<!-- File: docs/architecture/overview.html -->

<h1 align="center">ğŸ›ï¸ Architecture Overview â€” OMANIâ€‘Therapistâ€‘Voice</h1>

<hr>

<h2>ğŸ§  System Design</h2>
<p>
  OMANIâ€‘Therapistâ€‘Voice is a Flaskâ€‘based web application engineered to deliver culturally sensitive mental health support in Omani Arabic.<br>
  It processes user audio through a modular, multiâ€‘stage pipeline:
</p>
<ol>
  <li>ğŸ¤ Speechâ€‘toâ€‘Text (STT)</li>
  <li>ğŸ›¡ Safety Assessment</li>
  <li>ğŸ˜” Emotion Detection</li>
  <li>ğŸ’¬ Therapy Generation</li>
  <li>ğŸ”Š Textâ€‘toâ€‘Speech (TTS)</li>
</ol>
<p>
  Designed for maintainability and scalability, the architecture separates logic into distinct folders (<code>agents</code>, <code>api</code>, <code>utils</code>) with full logging and realâ€‘time performance monitoring.<br>
  The app runs at <a href="http://127.0.0.1:5000">http://127.0.0.1:5000</a> or offline via script. Docker provides deployment flexibility.
</p>

<hr>

<h2>ğŸ”‘ Key Components</h2>

<h3>ğŸ–¥ Web Interface</h3>
<ul>
  <li><strong>File:</strong> <code>src/ui/app.py</code></li>
  <li><strong>Role:</strong> Serves <code>index.html</code>, accepts audio via POST, converts WebM to WAV using <code>pydub</code>, invokes all pipeline stages.</li>
  <li><strong>Notes:</strong> Streams final audio with <code>send_file</code>. Supports <code>lang=ar</code> / <code>lang=en</code>.</li>
  <li><strong>Logging:</strong> Integrated via <code>src/utils/logger.py</code>, with 500â€‘error handling.</li>
</ul>

<h3>ğŸ§ Speechâ€‘toâ€‘Text (STT)</h3>
<ul>
  <li><strong>File:</strong> <code>src/api/stt/stt.py</code></li>
  <li><strong>Role:</strong> Azure Speech SDK transcribes <code>src/utils/output.wav</code>.</li>
  <li><strong>Mocking:</strong> Includes <code>mock_transcript.txt</code> for tests.</li>
  <li><strong>Config:</strong> Credentials from <code>src/api/config/azure_config.json</code>.</li>
  <li><strong>Settings:</strong> 16â€¯kHz mono WAV, optimized for Arabic.</li>
  <li><strong>Log Ref.:</strong> â€œLahola lahola ÙˆÙ„Ø§ Ù‚ÙˆØ©ØŸâ€ @ 12:31:09,823</li>
</ul>

<h3>ğŸ›¡ Safety Assessment</h3>
<ul>
  <li><strong>File:</strong> <code>src/agents/safety/safety_agent.py</code></li>
  <li><strong>Role:</strong> Flags harmful/crisis content via <code>normalize_arabic_text()</code>.</li>
  <li><strong>Preproc.:</strong> <code>src/utils/text_normalization.py</code> handles Arabic variants.</li>
  <li><strong>Log Ref.:</strong> 12:31:10,252</li>
</ul>

<h3>ğŸ˜” Emotion Detection</h3>
<ul>
  <li><strong>File:</strong> <code>src/agents/emotion/emotion_agent.py</code></li>
  <li><strong>Models:</strong>
    <ul>
      <li>Base HF model â†’ <code>models/arabic_emotion_model/</code></li>
      <li>Fineâ€‘tuned Omani â†’ <code>models/emotion_finetuned/</code></li>
    </ul>
  </li>
  <li><strong>Data:</strong> <code>data/mental_health_phrases.csv</code></li>
  <li><strong>Detection:</strong> Chooses highestâ€‘confidence emotion (â€œsadnessâ€ @ 0.99 @ 12:31:14,769)</li>
  <li><strong>Script:</strong> <code>fine_tune_emotion.py</code></li>
  <li><strong>Tests:</strong> <code>tests/unit/test_emotion_agent.py</code></li>
</ul>

<h3>ğŸ’¬ Therapy Generation</h3>
<ul>
  <li><strong>File:</strong> <code>src/agents/therapy/therapy_agent.py</code></li>
  <li><strong>LLM Backend:</strong> Uses <code>Groq-hosted Mixtral</code> for generating culturally appropriate CBT-style responses.</li>
  <li><strong>Prompt Logic:</strong> Dynamically injects Omani Arabic idioms from <code>src/utils/cultural_embeddings.py</code> (e.g., â€œØ§Ù„ØµØ¨Ø± Ù…ÙØªØ§Ø­ Ø§Ù„ÙØ±Ø¬â€) to ensure relevance and trust-building.</li>
  <li><strong>Dual-Model Strategy:</strong> Prompt chaining and response validation emulate GPT-4o + Claude Opus 4 behavior under API constraints.</li>
  <li><strong>Validation:</strong> Ensures responses align with Islamic values, therapeutic tone, and dialect sensitivity.</li>
  <li><strong>Log Reference:</strong> 12:31:14,882</li>
</ul>


<h3>ğŸ”Š Textâ€‘toâ€‘Speech (TTS)</h3>
<ul>
  <li><strong>File:</strong> <code>src/api/tts/tts.py</code></li>
  <li><strong>Role:</strong> Azure TTS converts therapy text to <code>src/utils/output_tts.wav</code>.</li>
  <li><strong>Voices:</strong> Omani Arabic; disabled in crisis cases.</li>
  <li><strong>Log Ref.:</strong> 12:31:15,637</li>
</ul>

<h3>âš™ï¸ Utilities</h3>
<ul>
  <li><strong>Logger:</strong> <code>src/utils/logger.py</code> â†’ unified logs (<code>pipeline.log</code>).</li>
  <li><strong>Monitoring:</strong> <code>src/utils/monitoring.py</code> â†’ stage latency & success rates.</li>
  <li><strong>Voice Capture:</strong> <code>src/utils/voice_capture.py</code> â†’ WebMâ†’WAV.</li>
  <li><strong>Normalization:</strong> <code>src/utils/text_normalization.py</code>.</li>
  <li><strong>Tokenization:</strong> <code>src/utils/tokenization.py</code>.</li>
</ul>

<hr>

<h2>ğŸ“¦ Deployment</h2>
<pre><code>docker build -t omani-therapist-voice infra/docker/Dockerfile .
docker run -p 5000:5000 omani-therapist-voice
</code></pre>

<hr>

<h2>âš™ï¸ Technical Specifications</h2>
<ul>
  <li>Pythonâ€¯3.9+</li>
  <li>Flask, transformers, langchainâ€‘groq, pydub, azureâ€‘cognitiveservicesâ€‘speech</li>
  <li>Models: HF BERT (Arabic), Groq LLM</li>
  <li>Latencyâ€¯<â€¯20â€¯s (monitored)</li>
</ul>

<hr>

<h2>ğŸ—‚ï¸ Project Structure</h2>
<pre class="project-structure"><code>
OMANIâ€‘Therapistâ€‘Voice/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ ui/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ data/
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture/overview.html
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ docker/
â”œâ”€â”€ .env           (exclude)
â”œâ”€â”€ requirements.txt
â””â”€â”€ pipeline.log   (exclude)
</code></pre>

<hr>

<h2>ğŸ›  Challenges & Fixes</h2>
<ul>
  <li><strong>Model Loading Lag:</strong> Preloaded models in <code>emotion_agent.py</code>.</li>
  <li><strong>TTS Cutoffs:</strong> Debug logs + Azure SDK fix; disabled in crisis.</li>
  <li><strong>Consent Flow:</strong> Checkbox + 400 error if missing.</li>
</ul>

<hr>

<h2>ğŸš€ Future Considerations</h2>
<ul>
  <li>Load balancing for scale.</li>
  <li>Expand emotion dataset.</li>
  <li>Implement bias mitigation per <code>bias_mitigation.md</code>.</li>
</ul>

<hr>

<h2>ğŸ™ Acknowledgments</h2>
<ul>
  <li>Hugging Face</li>
  <li>Azure Cognitive Services</li>
  <li>Groq</li>
</ul>

<hr>

<h2>ğŸ“œ Version History</h2>
<ul>
  <li><strong>JulyÂ 11,Â 2025:</strong> Safety alerts, tokenization, consent flow added.</li>
  <li><strong>JulyÂ 12,Â 2025:</strong> GitHub guidelines, refined overview.</li>
</ul>

<p class="footer-note">
  <strong>Exclude from GitHub:</strong> <code>.env</code>, <code>venv/</code>, <code>pipeline.log</code>, audio outputs, <code>__pycache__</code>.
</p>
